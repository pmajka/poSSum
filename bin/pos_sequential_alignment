#!/usr/bin/python
# -*- coding: utf-8 -*


"""
A sequential alignment workflow.

See the

Majka P, Wójcik DK. 2015. Possum—A Framework for Three-Dimensional
Reconstruction of Brain Images from Serial Sections. Neuroinformatics.
10.1007/s12021-015-9286-1
http://www.ncbi.nlm.nih.gov/pubmed/26687079

for detailed description of the workflow implemented in this script.
"""

import os
import sys

from optparse import OptionGroup
import copy

import networkx as nx

from possum.pos_common import r, IDENTITY_TRANSFORM_2D_STRING, flatten
from possum.pos_wrapper_skel import output_volume_workflow
from possum import pos_parameters
from possum import pos_wrappers


class sequential_alignment(output_volume_workflow):
    """
    A sequential alignment workflow.

    See the:

    Majka P, Wójcik DK. 2015. Possum—A Framework for Three-Dimensional
    Reconstruction of Brain Images from Serial Sections. Neuroinformatics.
    10.1007/s12021-015-9286-1
    http://www.ncbi.nlm.nih.gov/pubmed/26687079

    for detailed description of the workflow implemented in this script.
    """

    _f = {
        'raw_image': pos_parameters.filename('raw_image', work_dir='00_override_this', str_template='{idx:04d}.nii.gz'),
        'src_gray': pos_parameters.filename('src_gray', work_dir='00_source_gray', str_template='{idx:04d}.nii.gz'),
        'src_color': pos_parameters.filename('src_color', work_dir='01_source_color', str_template='{idx:04d}.nii.gz'),
        'part_naming': pos_parameters.filename('part_naming', work_dir='02_transforms', str_template='tr_m{mIdx:04d}_f{fIdx:04d}_'),
        'part_transf': pos_parameters.filename('part_transf', work_dir='02_transforms', str_template='tr_m{mIdx:04d}_f{fIdx:04d}_Affine.txt'),
        'comp_transf': pos_parameters.filename('comp_transf', work_dir='02_transforms', str_template='ct_m{mIdx:04d}_f{fIdx:04d}_Affine.txt'),
        'transf_center': pos_parameters.filename('transf_center', work_dir='10_centre_of_gravity', str_template='cog_m{mIdx:04d}_f{fIdx:04d}_Affine.txt'),
        'comp_transf_mask': pos_parameters.filename('comp_transf_mask', work_dir='02_transforms', str_template='ct_*_Affine.txt'),
        'resliced_gray': pos_parameters.filename('resliced_gray', work_dir='04_gray_resliced', str_template='{idx:04d}.nii.gz'),
        'resliced_gray_mask': pos_parameters.filename('resliced_gray_mask', work_dir='04_gray_resliced', str_template='%04d.nii.gz'),
        'resliced_color': pos_parameters.filename('resliced_color', work_dir='05_color_resliced', str_template='{idx:04d}.nii.gz'),
        'resliced_color_mask': pos_parameters.filename('resliced_color_mask', work_dir='05_color_resliced', str_template='%04d.nii.gz'),
        'out_volume_gray': pos_parameters.filename('out_volume_gray', work_dir='06_output_volumes', str_template='{fname}_gray.nii.gz'),
        'out_volume_color': pos_parameters.filename('out_volume_color', work_dir='06_output_volumes', str_template='{fname}_color.nii.gz'),
        'transform_report': pos_parameters.filename('transform_report', work_dir='06_output_volumes', str_template='{fname}.txt'),
        'graph_edges': pos_parameters.filename('graph_edges', work_dir='06_output_volumes', str_template='graph_edges_{sign}.csv'),
        'similarity': pos_parameters.filename('similarity', work_dir='06_output_volumes', str_template='similarity_{sign}.csv'),
         }

    _usage = ""

    # Define the magic numbers:
    __AFFINE_ITERATIONS = [10000, 10000, 10000, 10000, 10000]
    __DEFORMABLE_ITERATIONS = [0]
    __IMAGE_DIMENSION = 2
    __HISTOGRAM_MATCHING = True
    __MI_SAMPLES = 16000
    __VOL_STACK_SLICE_SPACING = 1
    __FORCE_SKIPPING_WEIGHT = 100

    def _initializeOptions(self):
        super(self.__class__, self)._initializeOptions()

        # Yes, it is extremely important to provide the slicing range.
        assert self.options.sliceRange, \
            self._logger.error(r("Slice range parameters (`--slices-range`) \
            are required. Please provide the slice range. "))

        # Define slices' range. All slices within given range will be
        # processed. Make sure that all images are available.
        self.options.slice_range = \
            range(self.options.sliceRange[0], self.options.sliceRange[1] + 1)

        # Verify if the reference slice index is provided and if ti is correct.
        # The reference slice index cannot be the same as either the starting
        # and the last slice index. This will cause an error.
        assert self.options.sliceRange[0] < self.options.sliceRange[2] and \
            self.options.sliceRange[2] < self.options.sliceRange[1], \
            self._logger.error(r("Incorrect reference slice index. \
            The reference slice index has to be larger than the first \
            slice index and smaller than the last slice index."))

        # Validate, if an input images directory is provided,
        # Obviously, we need to load the images in order to workflow them.
        assert self.options.input_image_dir, \
            self._logger.error(r("No input images directory is provided. \
            Please provide the input images directory (--input-images-directory)"))

        # Verify, if the provided image-to-image metric is provided.
        assert self.options.ants_image_metric.lower() in ['mi', 'cc', 'msq'], \
            self._logger.error(r("Provided image-to-image metric name is \
            invalid. Three image-to-image metrics are allowed: MSQ, MI, CC."))

    def _overrideDefaults(self):
        super(self.__class__, self)._overrideDefaults()

        # At the very beginning override the default dummy input images
        # directory by the actual images directory.
        self.f['raw_image'].override_dir = self.options.input_image_dir

        # Overriding the transformations directory
        # It might be usefull i.e. when one wants to save the transformation
        # to a different directory than the default one.
        # Note that directory names for two file types has to be switched.
        if self.options.transformations_directory is not False:
            self.f['part_naming'].override_dir = \
                self.options.transformations_directory
            self.f['part_transf'].override_dir = \
                self.options.transformations_directory
            self.f['comp_transf'].override_dir = \
                self.options.transformations_directory
            self.f['comp_transf_mask'].override_dir = \
                self.options.transformations_directory

        # The output volumes directory may be overriden as well
        # Note that the the output volumes directory stores also
        # transformation analyses plots.
        if self.options.output_volumes_directory is not False:
            self.f['out_volume_gray'].override_dir = \
                self.options.output_volumes_directory
            self.f['out_volume_color'].override_dir = \
                self.options.output_volumes_directory
            self.f['transform_report'].override_dir = \
                self.options.output_volumes_directory

        # Apart from just setting the custom output volumes directory, one can
        # also customize even the output filename of both, grayscale and
        # multichannel volumes! That a variety of options!
        if self.options.grayscale_volume_filename:
            self.f['out_volume_gray'].override_fname = \
                self.options.grayscale_volume_filename
        if self.options.multichannel_volume_filename:
            self.f['out_volume_color'].override_fname = \
                self.options.multichannel_volume_filename

    def launch(self):
        # Execute the parents before-execution activities
        super(self.__class__, self)._pre_launch()

        # Before launching the registration workflow check, if the intput
        # directory and all the input images exist. Note that the input image
        # inspection is performed in case of performing the actual
        # computations. In case of trial runs, no validation if performed.
        if self.options.dry_run is not True:
            self._inspect_input_images()

        # Prepare the input slices. Both, grayscale and rgb slices are prepared
        # simltaneously by a single routine. Slices preparation may be
        # disabled, switched off by providing approperiate command line
        # parameter. In that's the case, this step will be skipped.
        if self.options.source_slices_generation is True:
            self._generate_source_slices()

        # Generate transforms. This step may be switched off by providing
        # aproperiate command line parameter.
        if self.options.enable_transformations is True:
            self._calculate_transforms()

        # Composite transformations take relatively
        # small amount of time to compute:
        self._calculate_composite_transforms()

        # Reslice the input slices according to the generated transforms.
        # This step may be skipped by providing approperiate command line
        # parameter.
        if self.options.enable_reslice is True:
            self._reslice()

        # Stack both grayscale as well as the rgb slices into a volume.
        # This step may be skipped by providing approperiate command line
        # parameter.
        if self.options.enable_output_volumes is True:
            self._stack_output_images()

        # Run parent's post execution activities
        super(self.__class__, self)._post_launch()

    def _inspect_input_images(self):
        """
        Verify if all the files are availabe: All images have to be ailable. If
        the case is different, the workflow will not proceed and the user will
        be asked to supply the missing images.
        """
        self._logger.debug("Inspecting if all the input images are available.")

        # Iterate over all filenames and check if the file exists.
        for slice_index in self.options.slice_range:
            slice_filename = self.f['raw_image'](idx=slice_index)

            self._logger.debug("Checking for image: %s.", slice_filename)
            if not os.path.isfile(slice_filename):
                self._logger.error("File does not exist: %s. Exiting",
                                   slice_filename)
                sys.exit(1)

        # Ok, now we have to perform the same operation for the moving slices.
        # The idea is to locate the blank moving images. For these slices there
        # is no need to calculate any transformation (singe the are blank
        # anyway). Thus, a identity transformation is created for the blank
        # moving slices.
        self._logger.debug("Searching for blank images.")

        # Iterate over all reference slices and detect the number of voxels per
        # slice.
        self._slices_voxel_counts = {}

        # Iterate over all moving slices and detect the number of voxels per
        # slice.
        for slice_index in self.options.slice_range:
            command = pos_wrappers.image_voxel_count_wrapper(
                image=self.f['raw_image'](idx=slice_index),
                background=self.options.reslice_backgorund,
                voxel_sum=True)
            vox_count = float(command()['stdout'].strip())
            self._slices_voxel_counts[slice_index] = vox_count

    def _generate_identity_transformation(self, filename):
        """
        Generated an two dimensional identity transformation.
        """
        open(filename, 'w').write(IDENTITY_TRANSFORM_2D_STRING)

    def _generate_source_slices(self):
        """
        Generate source slices for the registration purposes. Both grayscale
        and multichannel images are generates by this routine.
        """

        self._logger.info("Performing source slice generation.")

        # The array collecting all the individual command into a commands
        # batch.
        commands = []

        # Iterate over all the slices and prepare aproperiate slice preparation
        # commands.
        for slice_number in self.options.slice_range:
            command = pos_wrappers.alignment_preprocessor_wrapper(
                input_image=self.f['raw_image'](idx=slice_number),
                grayscale_output_image=self.f['src_gray'](idx=slice_number),
                color_output_image=self.f['src_color'](idx=slice_number),
                registration_roi=self.options.registration_roi,
                registration_resize=self.options.registration_resize,
                registration_color=self.options.registration_color,
                median_filter_radius=self.options.median_filter_radius,
                invert_grayscale=self.options.invert_multichannel,
                invert_multichannel=self.options.invert_multichannel)
            commands.append(copy.deepcopy(command))

        self._logger.info("Executing the source slice generation commands.")
        # Execute the commands in a batch.
        self.execute(commands)

        self._logger.info("Source slice generation is completed.")

    def _calculate_transforms(self):
        """
        This rutine calculates the affine (or rigid transformations) for the
        sequential alignment. This step consists of two stages. The first stage
        calculates a partial transformation while the second stage composes the
        partial transformation into the composite transformations.

        The partial transformation 'connects' two consecutive slices and the
        composite trasformation binds given moving slice with the reference
        slice.

        Note that this routine does not apply the calculated transformations to
        the source images. This is done in further steps of processing.
        """

        self._logger.info("Generating transformations.")

        # Calculate partial transforms - get partial transformation chain;
        partial_transformation_pairs = \
            map(lambda idx: self._get_slice_pair(idx),
            self.options.slice_range)

        # Flatten the slices pairs
        partial_transformation_pairs =\
            list(flatten(partial_transformation_pairs))

        # If user decided to prealign the images by their centre of gravity
        # an additional series of transformations has to be carried out.
        if self.options.enable_moments_alignment:
            commands = map(lambda x: self._get_cog_alignment(*x),
                partial_transformation_pairs)
            commands = filter(None, commands)

            self._logger.info("Executing the centre of gravity transforms.")
            self.execute(commands)

        # Calculate affine transformation for each slices pair
        commands = map(lambda x: self._get_partial_transform(*x),
            partial_transformation_pairs)
        commands = filter(None, commands)
        self._logger.info("Executing the transformation commands.")
        self.execute(commands)

    def _get_cog_alignment(self, moving_slice_index, fixed_slice_index):
        """
        Get a single partial transform which computes a transformation of a
        given moving slice into a fixed slice by the images' centres of
        gravity.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int

        :param fixed_slice_index: fixed slice index
        :type fixed_slice_index: int

        :return: Registration command wrapper or False if given pair of
        sections will not be registered.
        """

        # Define the output cog transformation filename as it is used multiple
        # times in this method:
        output_cog_filename = \
            self.f['transf_center'](mIdx=moving_slice_index, fIdx=fixed_slice_index)

        if not self.options.override_transformations and \
           os.path.isfile(output_cog_filename):
            self._logger.info(r("A centre of gravity transformation for \
            sections. f=%d, m=%d already exists and \
            override_transformations is set to false. This transformation \
            will not be recalculated" %
            (moving_slice_index, fixed_slice_index)))
            return False

        if self._slices_voxel_counts[moving_slice_index] <= 0.0005 or \
           self._slices_voxel_counts[fixed_slice_index] <= 0.0005:
            self._generate_identity_transformation(output_cog_filename)
            self._logger.info("Blank moving slice found. f=%d,m=%d ." %
                              (moving_slice_index, fixed_slice_index))
            self._logger.info("An identity transform will be applied.")
            return False

        cog_transform_getter = pos_wrappers.align_by_center_of_gravity(
            fixed_image=self.f['src_gray'](idx=fixed_slice_index),
            moving_image=self.f['src_gray'](idx=moving_slice_index),
            output_transformation= \
                    self.f['transf_center'](mIdx=moving_slice_index,
                                            fIdx=fixed_slice_index))
        return copy.deepcopy(cog_transform_getter)

    def _calculate_composite_transforms(self):
        """
        Calculates the composite transformations which means transformations
        linking the reference slice with the processed one.
        """

        self._calculate_similarity()
        # Finally, calculate composite transforms
        commands = []
        for moving_slice_index in self.options.slice_range:
            commands.append(self._calculate_composite(moving_slice_index))
        self.execute(commands)

        self._logger.info("Done with calculating the transformations.")

    def _get_slice_pair(self, moving_slice_index):
        """
        Returns pairs of slices between which partial transformations will be
        calculated.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int
        """

        # Just convenient aliases
        i = moving_slice_index
        s, e, r = tuple(self.options.sliceRange)

        # Array holding pairs of transformations between which the
        # transformations will be calculated.
        retDict = []
        epsilon = self.options.graph_edge_epsilon

        if i == r:
            j = i
            retDict.append((i, j))
        if i > r:
            for j in list(range(i - epsilon, i)):
                if j <= e and i != j and j >= r:
                    retDict.append((i, j))
        if i < r:
            for j in list(range(i, i + epsilon + 1)):
                if j >= s and i != j and j <= r:
                    retDict.append((i, j))

        return retDict

    def _get_partial_transform(self, moving_slice_index, fixed_slice_index):
        """
        Get a single partial transform which registers given moving slice into
        a fixed slice.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int

        :param fixed_slice_index: fixed slice index
        :type fixed_slice_index: int

        :return: Registration command wrapper or False if given pair of
        sections will not be registered.
        """

        # Define the output transformation filename (just for convenience
        # as it is used a few times in the code:
        output_affine_filename = \
          self.f['part_transf'](mIdx=moving_slice_index, fIdx=fixed_slice_index)

        # If the transformation to be calculated already exists,
        # and override_transformations is set to false, the
        # new transformation will not be calculated and the existing
        # transformation file will be used:
        if not self.options.override_transformations and \
           os.path.isfile(output_affine_filename):
            self._logger.info(r("A transformation for \
            sections. f=%d, m=%d already exists and \
            override_transformations is set to false. This transformation \
            will not be recalculated" %
            (moving_slice_index, fixed_slice_index)))
            return False

        # Verify if both images contain actual image. If they do, proceed
        # normally. If a blank image has occured, generate an identity
        # transformation for this given pair of images.
        if self._slices_voxel_counts[moving_slice_index] == 0 or \
           self._slices_voxel_counts[fixed_slice_index] == 0:
            self._generate_identity_transformation(output_affine_filename)
            self._logger.info("Blank moving slice found. f=%d, m=%d ." %
                              (moving_slice_index, fixed_slice_index))
            self._logger.info("An identity transform will be applied.")
            return False

        # Define the registration settings: image-to-image metric and its
        # parameter, number of iterations, output naming, type of the affine
        # transformation.
        similarity_metric = self.options.ants_image_metric
        affine_metric_type = self.options.ants_image_metric
        metric_parameter = self.options.ants_image_metric_opt
        affine_iterations = self.__AFFINE_ITERATIONS
        output_naming = self.f['part_naming'](mIdx=moving_slice_index,
                                              fIdx=fixed_slice_index)

        # Yeah, I know this is not the most optimal way
        # to make a true/false string out of boolean value but ...
        use_rigid_transformation = str(self.options.use_rigid_affine).lower()

        # Ok, next we need to incorporate the centre-of-gravity prealignment
        # information if a user decided to switch on the prealignment step.
        initial_affine = None
        if self.options.enable_moments_alignment:
            initial_affine = \
            self.f['transf_center'](mIdx=moving_slice_index,
                                    fIdx=fixed_slice_index)

        # If there is a affine gradient descent command line parameter \
        # provided it has to be preprocessed before providing it
        # to the command line wapper.
        if self.options.affine_gradient_descent is None:
            gradient_descent_option = None
        else:
            gradient_descent_option = \
                self.options.affine_gradient_descent

        # Define the image-to-image metric.
        metrics = []
        metric = pos_wrappers.ants_intensity_meric(
            fixed_image=self.f['src_gray'](idx=fixed_slice_index),
            moving_image=self.f['src_gray'](idx=moving_slice_index),
            metric=similarity_metric,
            weight=1.0,
            parameter=metric_parameter)
        metrics.append(copy.deepcopy(metric))

        # Define the registration framework for 2D images,
        # without the deformable registration step, etc.
        registration = pos_wrappers.ants_registration(
            dimension=self.__IMAGE_DIMENSION,
            outputNaming=output_naming,
            iterations=self.__DEFORMABLE_ITERATIONS,
            affineIterations=affine_iterations,
            continueAffine=None,
            rigidAffine=use_rigid_transformation,
            imageMetrics=metrics,
            initialAffine=initial_affine,
            histogramMatching=str(self.__HISTOGRAM_MATCHING).lower(),
            miOption=[metric_parameter, self.__MI_SAMPLES],
            affineGradientDescent=gradient_descent_option,
            allMetricsConverge=None,
            affineMetricType=affine_metric_type)

        # Return the registration command.
        return copy.deepcopy(registration)

    def _calculate_similarity(self):
        """
        Calculate similarities between images for which the transformations
        were computed. Based on the similarity measures, a graph connecting
        individual images is created as saves for further calculations.

        The higher the lambda, the more reluctant the slice skipping is.
        """
        self._logger.info("Calculating the similarity between images.")

        # Create a helper function to simplify the loops below:
        def get_wrapper(fdx, mdx):
            wrapper = pos_wrappers.image_similarity_wrapper(
                reference_image=self.f['src_gray'](idx=fdx),
                moving_image=self.f['src_gray'](idx=mdx),
                affine_transformation=self.f['part_transf'](mIdx=mdx, fIdx=fdx))
            return copy.copy(wrapper)

        commands = []  # Will hold commands for calculating the similarity

        # Will hold (moving, fixed) images partial_transforms basically: all
        # partial transformations array
        partial_transforms = []

        self._logger.debug("Generating similarity measure warppers.")
        for moving_slice in self.options.slice_range:
            # Get all fixed images to which given moving slice will be aligned:
            tpair = list(flatten(self._get_slice_pair(moving_slice)))

            # Append partial transformations for given moving slice to the
            # global partial transformations array
            partial_transforms.append(tpair)

            # Generate wrapper for measuring similarity for a given partial
            # transformation.
            for mdx, fdx in tpair:
                commands.append(get_wrapper(fdx, mdx))

        # Execute and commands and workflow the similarity measurements.
        stdout, stderr = self.execute(commands)
        simmilarity = map(lambda x: float(x.strip()),
                          stdout.strip().split("\n"))

#       # ------------------------------------------
#       import numpy as np
#       simmilarity = np.sqrt(np.array(simmilarity))
#       input_min = simmilarity.min()
#       input_max = simmilarity.max()
#       print input_min, input_max
#       output_max = 0
#       output_min = -1
#       a = (output_max - output_min) / (input_max - input_min)
#       b = output_min
#       simmilarity = (simmilarity - input_min) * a + b
#       simmilarity = -1 * simmilarity
#       print simmilarity.min(), simmilarity.max()
#       simmilarity = list(simmilarity)
#       #------------------------------------------------

        simmilarity = dict(zip(flatten(partial_transforms), simmilarity))

        self._logger.debug("Generating graph edges.")
        graph_connections = []

        # Lambda defines slice skipping is preffered (lower l), or reluctant
        # to slice skipping (higher)
        l = self.options.graph_edge_lambda

        for (mdx, fdx), s in simmilarity.iteritems():
            w = (1.0 + s) * abs(mdx - fdx) * (1.0 + l) ** (abs(mdx - fdx))
            graph_connections.append((fdx, mdx, w))

        self._logger.info("Creating a graph based on image similarities.")

        # Generate the graph basen on the weight of the edges
        self.G = nx.DiGraph()
        self.G.add_weighted_edges_from(graph_connections)

        # Forcing skipping of some sections as defined in
        # the '--graph-skip-section' command line option:
        # This makes given section almost impossible to be included in any
        # of the transformation chanins for epsilon larger than one. At the
        # same time the section wiil have some transformation assigned
        # anyway.
        for s in self.options.graph_skip_section:
            for t in self.G.edge[s].keys():
                self.G.edge[s][t]['weight'] = self.__FORCE_SKIPPING_WEIGHT
                self._logger.info(r("Forcing node s=%d, t=%d \
                                    to be skipped."), s, t)

        self._logger.debug("Saving the graph to a file.")
        # Save the edges for some further analysis.
        nx.write_weighted_edgelist(self.G,
            self.f['graph_edges'](sign=self.signature))

        # Also, save the individual similarity metrics:
        simm_fh = open(self.f['similarity'](sign=self.signature), 'w')
        for (mdx, fdx), s in sorted(simmilarity.iteritems()):
            simm_fh.write("%d %d %f\n" % (mdx, fdx, s))
        simm_fh.close()

    def _get_transformation_chain(self, moving_slice_index):
        """
        Generate transformation chain based on the Dijkstra's shortest path
        algorithm.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int

        :return: chain of partial transformations connecting
                 given moving slice with the reference image
        :rtype: array
        """

        i = moving_slice_index
        s, e, r = tuple(self.options.sliceRange)

        # Calculate shortest paths between individual slices
        slice_paths = nx.all_pairs_dijkstra_path(self.G)

        # Get the shortest path linking given moving slice with the reference
        # slice.
        path = list(reversed(slice_paths[r][i]))
        chain = []

        # In case we hit a reference slice :)
        if i == r:
            chain.append((r, r))

        # For all the other cases collect partial transforms.
        for step in range(len(path) - 1):
            chain.append((path[step], path[step + 1]))

        return chain

    def _calculate_composite(self, moving_slice_index):
        """
        Composes individual partial transformations into composite
        transformation registering provided moving slice to the reference
        image.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int
        """

        # The transformation chain is a sequence of pairs of (fixed, moving)
        # slices. This sequence links the reference slices with given moving
        # slice.
        transformation_chain = \
            self._get_transformation_chain(moving_slice_index)

        # Initialize the partial transforms array and then collect all partial
        # transformations constituting given composite transformation.
        partial_transformations = []
        for (m_slice, r_slice) in transformation_chain:
            partial_transformations.append(
                self.f['part_transf'](mIdx=m_slice, fIdx=r_slice))

        # Define the output transformation filename
        composite_transform_filename = \
            self.f['comp_transf'](mIdx=moving_slice_index, fIdx=r_slice)

        # Initialize and define the composite transformation wrapper
        command = pos_wrappers.ants_compose_multi_transform(
            dimension=self.__IMAGE_DIMENSION,
            output_image=composite_transform_filename,
            deformable_list=[],
            affine_list=partial_transformations)

        return copy.deepcopy(command)

    def _reslice(self):
        """
        Reslice input images according to composed transformations. Both,
        grayscale and multichannel images are resliced. Also reslicing of both
        volumes can be switched of when required - but this is set somewhere
        else :)
        """

        # Reslicing grayscale images.  Reslicing multichannel images. Collect
        # all reslicing commands into an array and then execute the batch.
        self._logger.info("Reslicing grayscale images.")
        commands = []
        for slice_index in self.options.slice_range:
            commands.append(self._reslice_grayscale(slice_index))
        self.execute(commands)

        # Reslicing multichannel images. Again, collect all reslicing commands
        # into an array and then execute the batch.
        self._logger.info("Reslicing multichannel images.")
        commands = []
        for slice_index in self.options.slice_range:
            commands.append(self._reslice_color(slice_index))
        self.execute(commands)

        # Yeap, it's done.
        self._logger.info("Finished reslicing.")

    def _reslice_grayscale(self, slice_number):
        """
        Reslice grayscalce slice of the index `slice_number`.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int

        :return: Command for reslicing given slice with the calculated
                 transform.
        :rtype: `pos_wrappers.command_warp_grayscale_image`
        """

        # Define all the filenames required by the reslice command
        moving_image_filename = self.f['src_gray'](idx=slice_number)
        resliced_image_filename = self.f['resliced_gray'](idx=slice_number)
        reference_image_filename = self.f['src_gray'](
            idx=self.options.slice_range[2])
        transformation_file = self.f['comp_transf'](
            mIdx=slice_number, fIdx=self.options.sliceRange[2])

        # Get output volume region of interest (if such region is defined)
        region_origin_roi, region_size_roi =\
            self._get_output_volume_roi()

        # And finally initialize and customize reslice command.
        command = pos_wrappers.command_warp_grayscale_image(
            reference_image=reference_image_filename,
            moving_image=moving_image_filename,
            transformation=transformation_file,
            output_image=resliced_image_filename,
            background=self.options.reslice_backgorund,
            interpolation=self.options.reslice_interpolation,
            resampling=self.options.reslicing_resampling,
            region_origin=region_origin_roi,
            region_size=region_size_roi)
        return copy.deepcopy(command)

    def _reslice_color(self, slice_number):
        """
        Reslice multichannel image with the given `slice_number`.

        :param moving_slice_index: moving slice index
        :type moving_slice_index: int

        :return: Command for reslicing given slice with the calculated
                 transform.
        :rtype: `pos_wrappers.command_warp_grayscale_image`
        """

        # Define all the filenames required by the reslice command
        moving_image_filename = self.f['src_color'](idx=slice_number)
        resliced_image_filename = self.f['resliced_color'](idx=slice_number)
        reference_image_filename = self.f['src_gray'](
            idx=self.options.slice_range[2])
        transformation_file = self.f['comp_transf'](
            mIdx=slice_number, fIdx=self.options.sliceRange[2])

        # Get output volume region of interest (if such region is defined)
        region_origin_roi, region_size_roi =\
            self._get_output_volume_roi()

        # And finally initialize and customize reslice command.
        command = pos_wrappers.command_warp_rgb_slice(
            reference_image=reference_image_filename,
            moving_image=moving_image_filename,
            transformation=transformation_file,
            output_image=resliced_image_filename,
            region_origin=region_origin_roi,
            region_size=region_size_roi,
            resampling=self.options.reslicing_resampling,
            background=self.options.reslice_backgorund,
            interpolation=self.options.reslice_interpolation,
            inversion_flag=self.options.invert_multichannel)

        # Return the created command line parser.
        return copy.deepcopy(command)

    def _get_output_volume_roi(self):
        """
        Define output images stack origin and and size according to the
        providing command line arguments. If provided, the resliced images are
        cropped before stacking into volumes. Note that when the slices are
        cropped their origin is preserved. That should be taken into
        consideration when origin of the stacked volume if provided.

        When the output ROI is not defined, nothing special will happen.
        Resliced images will not be cropped in any way.
        """

        # Define output ROI based on provided command line arguments, if such
        # arguments are provided.
        if self.options.output_volume_roi:
            region_origin_roi = self.options.output_volume_roi[0:2]
            region_size_roi = self.options.output_volume_roi[2:4]
        else:
            region_origin_roi = None
            region_size_roi = None

        return region_origin_roi, region_size_roi

    def _get_generic_stack_slice_wrapper(self, mask_type, ouput_filename_type):
        """
        Return generic command wrapper suitable either for stacking
        grayscale images or multichannel images. Aproperiate command line
        wrapper is returned depending on provided `mask_type` and
        `output_filename_type`.  The command line wrapper is prepared mostly
        based on the command line parameters which are common between both
        images stacks thus so there is no need to parametrize them
        individually.

        :param mask_type: mask type determining which images stack will be
                          converted into a volume.
        :type mask_type: str

        :param ouput_filename_type: output filename naming scheme.
        :type ouput_filename_type: str
        """

        # Assign some usefull aliases.
        start, stop, reference = self.options.sliceRange

        # Define the output volume filename. If no custom colume name is
        # provided, the filename is based on the provided processing
        # parameters. In the other case the provided custom filename is used.
        output_filename = self.f[ouput_filename_type](fname=self.signature)

        # Define the warpper according to the provided settings.
        command = pos_wrappers.stack_and_reorient_wrapper(
            stack_mask=self.f[mask_type](),
            slice_start=start,
            slice_end=stop,
            slice_step=self.__VOL_STACK_SLICE_SPACING,
            output_volume_fn=output_filename,
            permutation_order=self.options.output_volume_permute_axes,
            orientation_code=self.options.output_volume_orientation,
            output_type=self.options.output_volume_scalar_type,
            spacing=self.options.output_volume_spacing,
            origin=self.options.output_volume_origin,
            interpolation=self.options.output_volume_interpolation,
            resample=self.options.output_volume_resample)

        # Return the created parser.
        return copy.deepcopy(command)

    def _stack_output_images(self):
        """
        Execute stacking images based on grayscale and multichannel images.
        Both resliced image stacks are turned into volumetric files by this
        method.
        """

        self._logger.info("Stacking the grayscale image stack.")
        command = self._get_generic_stack_slice_wrapper(
                    'resliced_gray_mask', 'out_volume_gray')
        self.execute(command)

        self._logger.info("Stacking the multichannel image stack.")
        command = self._get_generic_stack_slice_wrapper(
                    'resliced_color_mask', 'out_volume_color')
        self.execute(command)

        self._logger.info("Reslicing is done.")

    def _get_parameter_based_output_prefix(self):
        """
        Generate filename prefix base on the provided processing parameters.
        The filename prefix is used when no other naming scheme is provided.
        """

        # As you can see the generation of the output filename prefix is
        # straigthforward but pretty tireingsome.
        filename_prefix = "sequential_alignment_"

        filename_prefix += "s-%d_e-%d_r-%d_" % tuple(self.options.sliceRange)

        try:
            filename_prefix += "ROI-%s" % "x".join(map(str, self.options.registration_roi))
        except:
            filename_prefix += "ROI-None"

        try:
            filename_prefix += "_Resize-%s" % "x".join(map(str, self.options.registration_resize))
        except:
            filename_prefix += "_Resize-None"

        filename_prefix += "_Color-%s" % self.options.registration_color

        try:
            filename_prefix += "_Median-%s" % "x".join(map(str, self.options.median_filter_radius))
        except:
            filename_prefix += "_Median-None"

        filename_prefix += "_Metric-%s" % self.options.ants_image_metric
        filename_prefix += "_MetricOpt-%d" % self.options.ants_image_metric_opt
        filename_prefix += "_Affine-%s" % str(self.options.use_rigid_affine)

        filename_prefix += "_eps-%d_lam%02.2f" % \
            (self.options.graph_edge_epsilon, self.options.graph_edge_lambda)

        try:
            filename_prefix += "outROI-%s" % "x".join(map(str, self.options.output_volume_roi))
        except:
            filename_prefix += "outROI-None"

        return filename_prefix

    signature = property(_get_parameter_based_output_prefix)

    @classmethod
    def _getCommandLineParser(cls):
        """
        """
        parser = output_volume_workflow._getCommandLineParser()

        usage_string = r("usage: %prog --slices-range first last reference \
            --input-images-directory input_directory [other options]")

        obligatory_options = OptionGroup(parser, 'Obligatory parameters')
        obligatory_options.add_option('--slices-range', default=None,
            type='int', dest='sliceRange', nargs=3,
            help=r('Slice range, Requires three integers: start index, \
            stop index, reference section index. Requires three integers.'))
        obligatory_options.add_option('--input-images-directory', default=None,
            type='str', dest='input_image_dir',
            help=r('The directory from which the input slices will be read. \
            The directory has to contain images named \
            according to "%04d.nii.gz" scheme.'))

        source_processing = OptionGroup(parser, 'Source data processing')

        source_processing.add_option('--enable-sources-slices-generation',
            default=True, dest='source_slices_generation', action='store_true',
            help=r('Enable / disable generation of the source sections. \
            Such sections are section which will be used as the \
            input for the registration.'))
        source_processing.add_option('--disable-sources-slices-generation',
            default=True, dest='source_slices_generation',
            action='store_false')

        source_processing.add_option('--registration-color-channel',
            dest='registration_color', default='blue', type='choice',
            choices=['r', 'g', 'b', 'red', 'green', 'blue'],
            help=r('For the RGB input images selects a color channel on \
            which registration will be performed. This parameter has no \
            meaning for when a set of grayscale images is provided as input \
            Allowed values: r/red, g/green, b/blue.'))
        source_processing.add_option('--median-filter-radius',
            dest='median_filter_radius', default=None, type='int', nargs=2,
            help=r('Determined the size of the median filter which will be \
            used smooth the raw input images during preprocessing \
            for the registration. Median filtering is applied for both, \
            fixed and moving image. Provide two integer values, e.g. 2 2. \
            The values do not have to be the same. In such case you will get \
            an anisotropic median smoothing. By default, no median \
            filtering will be applied.'))
        source_processing.add_option('--invert-multichannel',
            dest='invert_multichannel', default=None,
            action='store_const', const=True,
            help=r('Inverts (e.g. 255->0, 0->255) during processing the \
            images before the registation. This switch will apply the \
            inversion for both: graysale and rgb images.'))
        source_processing.add_option('--registration-roi',
            dest='registration_roi', default=None, type='int', nargs=4,
            help=r('ROI of the input images in pixels wich will be used \
            to define the input image region of interest based on which \
            the registration will be carried on. Note that the provided \
            region has to be a valid region in all the images provided \
            in the input stack. Four integers are required: ox, oy, sx, sy'))

        registration_options = OptionGroup(parser, 'Registration options')

        registration_options.add_option('--enable-transformations', default=True,
            dest='enable_transformations', action='store_true',
            help='Determined if the actual registration will be conducted.')
        registration_options.add_option('--disable-transformations', default=True,
            dest='enable_transformations', action='store_false')
        registration_options.add_option('--enable-moments', default=False,
            dest='enable_moments_alignment', action='store_true',
            help=r('Enable prealigning the images by their centre of gravity. \
            Note that the images have to have dark (0) background \
            with a bright (positive) content to make \
             this procedure behave correctly.'))
        registration_options.add_option('--disable-moments', default=False,
            dest='enable_moments_alignment', action='store_false',
            help=r('Enable prealigning the images by their centre \
            of gravity. Note that the images have to have dark (0) \
            background with a bright (positive) content.'))

        registration_options.add_option('--transformations-directory',
            default=False, dest='transformations_directory', type="str",
            help=r('Use provided transformation directory \
            instead of the default one.'))
        registration_options.add_option('--override-transformations',
            default=False, dest='override_transformations',
            action='store_true', help=r('Causes the workflow to override \
            existing transformations in the --transformations-directory. \
            By default, such transformations are not overriden. A typical \
            usage is with the --transformations-directory switch to preserve \
            or erase the existing transformations during consecutive series \
            of reconstructions.'))
        registration_options.add_option('--registration-resize',
            dest='registration_resize', default=None, type='float',
            help=r('Scaling factor for the source image used for \
            registration. Float between 0 and 1.'))
        registration_options.add_option('--use-rigid-affine', default=False,
            dest='use_rigid_affine', action='store_const', const=True,
            help='Use rigid affine transformation.')
        registration_options.add_option('--ants-image-metric', default='MI',
            type='choice', dest='ants_image_metric', choices=['MI', 'CC', 'MSQ'],
            help=r('ANTS affine image to image metric. \
            Three values are allowed: CC, MI, MSQ.'))
        registration_options.add_option('--ants-image-metric-opt', default=32,
            type='int', dest='ants_image_metric_opt',
            help=r('Parameter of ANTS i2i metric. Makes a sense only when \
            provided metric can be customized.'))
        registration_options.add_option('--affine-gradient-descent',
            default=None, type='float',
            dest='affine_gradient_descent', nargs=4,
            help=r('Grandient descent optimizers coefficients. \
            Check out the ANTS documentation for the meaning \
            and applications of this parameter.'))
        registration_options.add_option('--graph-edge-lambda', default=0.0,
            dest='graph_edge_lambda', action='store', type="float",
            help=r('Provedes lambda value for the graph edges generation. \
            A small positive lambda value are required.'))
        registration_options.add_option('--graph-edge-epsilon', default=1,
            dest='graph_edge_epsilon', action='store', type="int",
            help=r('Provedes epsilon value for the graph edges generation. \
            An small integer is required e.g. 1-5'))
        registration_options.add_option('--graph-skip-section', default=[],
            dest='graph_skip_section', action='append', type="int", nargs=1,
            help=r('Forces the section to be skipped in the shorest path \
            calculation by assigning graph edge of some crazy high value. \
            Note that still an appropriate value of the epsilon has to be \
            provided in order to achieve the skipping. This switch has to be \
            invoked multiple times if multiple sections are to \
            be force-skipped.'))

        reslicing_options = OptionGroup(parser, 'Reslicing options')

        reslicing_options.add_option('--enable-reslice', default=True,
            dest='enable_reslice', action='store_true',
            help='Supress generating grayscale volume')
        reslicing_options.add_option('--disable-reslice', default=True,
            dest='enable_reslice', action='store_false')

        reslicing_options.add_option('--reslice-backgorund', default=None,
            type='float', dest='reslice_backgorund',
            help=r('Background color. A float and / or negarive \
            values will probablu work, but unless you have to really \
            just provide an integer.'))
        reslicing_options.add_option('--reslice-interpolation',
            dest='reslice_interpolation', default=None, type='choice',
            choices=['Cubic', 'Linear', 'NearestNeighbor', 'Sinc'],
            help=r('Interpolation during applying the transforms \
            to individual slices.'))
        reslicing_options.add_option('--reslice-resampling',
            dest='reslicing_resampling', default=None, nargs=2,
            type=float, help=r("Resampling during applying transforms to \
            individual sections expressed in precents. To be exact applied \
            after the image has been transformed and optioenally cropped \
            Provide two positive non-zero float values."))
        reslicing_options.add_option('--output-volume-roi', default=None,
            type='int', dest='output_volume_roi',  nargs=4,
            help=r('ROI of the output volume. This is how the individual \
            images after reslicing will be cropped before stacking them \
            into a final stack. Note that this ROI has to be defined having \
            in mind the the registration ROI. Basically, first the \
            registration ROI is applied and then the output volume ROI. \
            Provide four positive integers: ox oy sx sy. \
            Note that the provided values have to make sense \
            a definition of a region, otherwise a \
            terrible error will occur.'))

        output_volume_opts = OptionGroup(parser, 'Output volume options.')

        output_volume_opts.add_option('--enable-output-volumes',
            default=True, dest='enable_output_volumes', action='store_true',
            help='Supress generating color / rgb / multichannel volume.')
        output_volume_opts.add_option('--disable-output-volumes', default=True,
            dest='enable_output_volumes', action='store_false')

        output_volume_opts.add_option('--output-volumes-directory',
            default=False, dest='output_volumes_directory', type="str",
            help=r('Directory in which the reconstruction \
            results will be sored.'))
        output_volume_opts.add_option('--grayscale-volume-filename',
            default=False, dest='grayscale_volume_filename', type='str',
            help='Filename for the output grayscale volume.')
        output_volume_opts.add_option('--multichannel-volume-filename',
            default=False, dest='multichannel_volume_filename', type='str',
            help='Filename for the output multichannel (rgb) volume.')

        parser.add_option_group(obligatory_options)
        parser.add_option_group(source_processing)
        parser.add_option_group(registration_options)
        parser.add_option_group(reslicing_options)
        parser.add_option_group(output_volume_opts)

        return parser

if __name__ == '__main__':
    options, args = sequential_alignment.parseArgs()
    workflow = sequential_alignment(options, args)
    workflow.launch()
